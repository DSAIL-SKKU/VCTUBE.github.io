    <div class="sixteen columns">
      <h1>What is VCTUBE?</h1>
      <article>
          <p>
           VCTUBE is open-source Python library, that can automatically generate <audio, text> pair speech data from a given Youtube video URL
          </p>
      </article>
    </div>

<br>
<div class="sixteen columns">
      <h1>Why We Need VCTUBE?</h1>
      <article>
          <p>
            Recent studies have shown that Text-to-Speech (TTS) systems based on deep neural networks (e.g., Tacotron, Deep Voice, etc.) can generate human-like speech with high quality [1, 2]. However, it has been reported that training such a deep learning
model to generate human-like speech requires a large amount of speech data, e.g., at least 10 hours of <audio, text> pair data to generate high quality speech [3]. In practice, collecting and processing such a large amount of speech data is challenging.
            <br><br>
            <em>Data anonymization: </em> All the user information is anonymized, hence no personally identifiable information was not identified; we followed all the anonymization process guided by the Sungkyunkwan University Institutional Review Board (IRB).
          </p><br>

          <div style="text-align:center; margin-bottom: 10px;">
            <img src="{{ site.website_full }}static/img/reddit_cnn.jpg" style="width:400px;"><br>
            <div>An architecture of the proposed CNN-based classifcation model.</div>
          </div>

          <p>
            <em>Classification models: </em> We developed six binary classification models, each of which categorizes a user' specific post into one of the following subreddits: r/depression, r/Anxiety, r/bipolar, r/BPD, r/schizophrenia, and r/autism.
            Our conjecture is that a user who suffers from a specific mental problem writes a post on the corresponding subreddit that deals with the problem.
            Therefore, we developed six independent binary classification models for each symptom to improve the performance.
            By developing six independent models for each mental disorder, each of which uses data where users suffer from only one particular mental problem, we were able to accurately identify a user's potential mental state.
            <br><br>
            We divided our dataset into training (80%) and testing (20%) sets. We used two well-known classifiers, XGBoost and Convolutional Neural Network (CNN).
            Note that we excluded the posts of users who wrote posts across multiple subreddits in learning phase.
          </p>



      </article>
    </div>
    <div class="row">
      <div class="eight columns">
          <h1>Dataset</h1>
            <ul>
              <li><em>Posts of Mental-health-related Subreddits (.csv format)</em></li>
              <li>- Data schema is written in the first row of data.</li>
              <li>- We are only allowed to distribute the data for the research purpose. Send an email to <a href="{{ site.email_full }}">jinakim@g.skku.edu</a> with the [SR-DataAccess] title.</li>
            </ul>
      </div>
      <div class="seven columns">
        <h1>Paper URL</h1>
        <em><a href="NOt now">INTERSPEECH 2020 (Published:  2020)</a></em>
        <br><br>

      </div>
    </div>

</section>

Â© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
